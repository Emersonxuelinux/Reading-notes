#应用案例剖析
##1、图片上加数字
	#!/usr/bin/env python
	#coding:utf-8
	myPath = "./"
	fontPath = "./"
	inputFile = "xwp.jpg"
	outputFile = "output.jpg"
	
	import Image,ImageFont,ImageDraw
	#打开图片
	im = Image.open(myPath+inputFile)
	draw = ImageDraw.Draw(im)
	#根据图片大小确定字体大小
	fontsize = min(im.size)/4
	#加文字
	font = ImageFont.truetype(fontPath+"KhmerOS.ttf",fontsize)
	draw.text((im.size[0]-fontsize,0),'5',font=font,fill=(255,0,0))
	im.save(myPath+outputFile,"jpeg")
	
##2、生成随机数
	#!/usr/bin/env python
	#coding:utf-8
	
	import  string,random
	
	# 激活码中的字符和数字
	field = string.letters + string.digits
	
	# 获得四个字符和数字的随机组合
	def getRandom():
	    return "".join(random.sample(field, 4))
	
	# 生成的每个激活码中有几组
	def concatenate(group):
	    return "-".join([getRandom() for i in range(group)])
	
	# 生成n组激活码
	def generate(n):
	    return [concatenate(4) for i in range(n)]
	
	if __name__ == '__main__':
	    print generate(200)
	    
##3、统计单词
	#! /usr/bin/env python
	#coding:utf-8
	
	import re
	from collections imoort Counter
	FILESOURCE = './mediao/abc.txt'
	
	def getMostCommonWord(articlefilesource):
		'''输入一个英文的纯文本文件，统计其中的单词出现的个数'''		pattern =r'''[A-Za-z]+|\$?\d+%?$'''		with open(articlefilesource) as f:
			r = re.findall(pattern,f.read())			return Counter(r).most_common()
		
	if __name__ == '__main__':
		print getMostCommonWord(FILESOURCE)    
		
##4、最重要的词
目录下多个txt文件，找出词出现频率最高的

	#! /usr/bin/env python
	#coding:utf-8
	
	import re,os
	from collections import Counter
	
	#目标文件所在目录
	FILE_PATH = './media/countword'
	
	def getCounter(articlefilesource):
    '''输入一个英文的出文本文件，统计其中的单词出现的个数'''
    pattern = r'''[A-Za-z]+|\$?\d+%?$'''
    with open(articlefilesource) as f:
        r = re.findall(pattern, f.read())
        return Counter(r)

	# 过滤词
	stop_word = ['the', 'in', 'of', 'and', 'to', 'has', 'that', 's', 'is', 'are', 'a', 'with', 'as', 'an']		
	def run(FILE_PATH):
	    # 切换到目标文件所在目录
	    os.chdir(FILE_PATH)
	    # 遍历该目录下的txt文件
	    total_counter = Counter()
	    for i in os.listdir(os.getcwd()):
	        if os.path.splitext(i)[1] == '.txt':
	            total_counter += getCounter(i)
	
	    # 排除stopword的影响
	    for I in stop_word:
	        total_counter[i] = 0
	    print total_counter.most_common()[0][0]
	    
    if __name__ == '__main__':
        run(FILE_PATH)	
        
##5、批量图片处理
你有一个目录，装了很多图片，把他们的尺寸编程都不大于IPhone5分辨率的大小

思路：遍历给出目录下的图片，把大于IPhone5分辨率的图片进行缩放。使用Python的PIL库对图片进行处理，IPhone5屏幕分辨率为640x1136，将大于该分辨率的图片按照一定比例缩放至适合大小并保存

***如果在mac下导入Image为from PIL import Image***

	#！/usr/bin/env python
	#coding:utf-8
	import Image,os
	
	#源目录
	#myPath = './media/srcimg/'
	myPath = '/home/itcast/workspace/chuanzhi/openlessons/demo_python/media/srcimg/'
	#输出目录
	#outPath = './media/destimg/'
	outPath = '/home/itcast/workspace/chuanzhi/openlessons/demo_python/media/destimg/'
	
	def processImage(filesource,destsource,name,imgtype):
		'''
		filesource是存放待转换图片的目录
		destsource是存放输出转换后图片的目录
		name是文件名
		imgtype是文件类型
		'''
		
		imgtype = 'jpeg' if imgtype == '.jpg' else 'png'
		#打开图片
		im = Image.open(filesource+name)
		#缩放比例
		rate = max(im.size[0]/640.0 if im.size[0]>640 else 0,im.size[1]/1136.0 if im.size[1]>1136 else 0)
		if rate:
			im.thumbnail((im.size[0]/rate,im.size[1]/rate))
		im.save(destsource+name,imgtype)
	
	def run():
		#切换到源目录，遍历源目录下所有图片
		os.chdir(myPath)
		for i in os.listdir(os.getcwd()):
			#检查后缀
			postfix = os.path.splitext(i)[1]
			if postfix == '.jpg' or postfix == '.png':
				processImage(myPath,outPath,i,postfix)
	
	if __name__ == '__main__':
		run()	
	
##6、统计代码行数（注释，空行，总行数）
思路：获取目录，然后遍历目录下的代码文件，逐个统计每个文件的代码，然后最后汇总输出

	#! /usr/bin/env python
	#coding:utf-8
	
	import os,re
	
	#代码所在目录
	FILE_PATH = './'
	
	def analyze_code(codefilesource):
		'''
		打开一个py文件，统计其中的代码行数，包括空行和注释
		返回含该文件总行数，注释空行，空行数的列表
		'''
		
		total_line = 0
		comment_line = 0
		blank_line = 0
		with open(codefilesource) as f:
			lines = f.readlines()
			total_line = len(lines)
			line_index = 0
			#遍历每一行
			while line_index<total_line:
				line = lines[line_index]
				#检查是否为注释
				if line.startswith("#"):
					comment_line += 1
				elif re.match("\s*'''",line) is not None:
					comment_line += 1
					while re.match(".*'''$",line) is None:
						line = lines[line_index]
						comment_line += 1
						line_index += 1
				#检查是否为空行
				elif line  == "\n":
					blank_line += 1
				line_index += 1
		print "在%s中："%codefilesource
		print "代码行数：",total_line
		print "注释行数:",comment_line,"占%0.2f%%" % (comment_line*100.0/total_line)
		print "空行数：",blank_line,"占%0.2f%%" % (blank_line*100.0/total_line)
		return [total_line,comment_line,blank_line]
		
	def run(FILE_PATH):
		#切换到code所在目录
		os.chdir(FILE_PATH)
		#遍历该目录下的py文件
		total_lines = 0
		total_comment_lines = 0
		total_blank_lines = 0
		for i in os.listdir(os.getcwd()):
			if os.path.splitext(i)[1] == '.py':
				line = analyze_code(i)
				total_lines,total_comment_lines,total_blank_lines = total_lines + line[0],total_comment_lines+line[1],total_blank_lines+line[2]
		print "总代码行数：",total_lines
		print "总注释行数：",total_comment_lines,"占%0.2f%%" %(total_comment_lines*100.0/total_lines)
		print "总空行数：",total_blank_lines,"占%0.2f%%" %(total_blank_lines*100.0/total_lines)
	
	if __name__ == '__main__':
		run(FILE_PATH)
	
##7、提取html正文内容
思路：我把这里的正文理解为网页中主要内容，那么怎么去抓取这个内容呢？我一开始的想法是利用beautifulsoup来解析网页，但是又想到如果要抽取正文的话这样做还设计比较复杂的算法，而且对于不同的网页来说效果可能做不到很好。后来我发现了Python-goose(Github)这个神奇，它是基于NLTk和Beautiful Soup的，分别是文本处理和HTML解析的领导者，目标是给定任意资讯文章或者任意文章类的网页，不仅提取文章的主题，同时提取出所有元素信息以及图片等信息，支持中文网页（用到了结巴分词）。这个正负号要求，所以直接拿来用了。
	
安装python goose:
	
	git clone https://github.com/grangier/python-goose.git
	cd python-goose
	pip install -r requirements.txt
	python setup.py install		
	
源码：

	#! /usr/bin/env python
	# coding:utf-8
	from goose import Goose
	from goose.text import StopWordsChinese
	import sys
	reload(sys)
	sys.setdefaultencoding("utf-8")
	
	#要分析的网页url
	url = 'https://linux.cn/article-6717-1.html'
	def extract(url):
	    '''
	    提取网页正文
	    '''
	    g = Goose({'stopwords_class':StopWordsChinese})
	    article = g.extract(url=url)
	    return article.cleaned_text
	
	if __name__=='__main__':
	    print extract(url)

##8、生成验证码图片
思路：先随机生成验证码，然后利用python的PIL库画出这个激活码的图片，具体点就是创建画布，加验证码的字上去，增加噪点进行干燥，再进行模糊处理，接着保存到名字为验证码的图片中。
	
	#! /usr/bin/env python
	# coding:utf-8
	from PIL import Image,ImageDraw,ImageFont,ImageFilter
	import string,random
	
	fontPath = "./media/"
	
	#获得随机个字母
	def getRandomChar():
	    return [random.choice(string.letters) for _ in range(4)]
	
	#获得颜色
	def getRandomColor():
	    return (random.randint(30,100),random.randint(30,100),random.randint(30,100))
	
	#获得验证码图片
	def getCodePicture():
	    width = 240
	    height = 60
	    #创建画布
	    image = Image.new('RGB',(width,height),(180,180,180))
	    font = ImageFont.truetype(fontPath+'dnyb.ttf',40)
	    draw = ImageDraw.Draw(image)
	    #创建验证码对象
	    code = getRandomChar()
	    #把验证码放到画布上
	    for t in range(4):
	        draw.text((60*t+10,0),code[t],font=font,fill=getRandomColor())
	    #填充噪点
	    for _ in range(random.randint(1500,3000)):
	        draw.point((random.randint(0,width),random.randint(0,height)),fill=getRandomColor())
	    #模糊处理
	    image = image.filter(ImageFilter.BLUR)
	    #保存名字为验证码的图片
	    image.save("".join(code)+'.jpg','jpeg');
	
	if __name__=='__main__':
    	getCodePicture()

					
					
		
	
